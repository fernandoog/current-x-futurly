{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "01-Current-GPT2-generate.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Current.cam workshop - Volumetric Personas\n",
    "## GPT-2 Text Generation \n",
    "\n",
    "Made by [Artem Konevskikh](http://aiculedssul.net/) for [Current.cam](https://current.cam/)\n",
    "\n",
    "Based on notebook by [Max Woolf](http://minimaxir.com). For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VM69Hoc5j27B"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-du42C9dZsEy",
    "cellView": "form"
   },
   "source": [
    "#@title Imports\n",
    "#@markdown By running this cell we are loading libraries needed to work with GPT2\n",
    "!pip install git+https://github.com/minimaxir/gpt-2-simple\n",
    "import gpt_2_simple as gpt2\n",
    "from datetime import datetime\n"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/minimaxir/gpt-2-simple 'C:\\Users\\ferna\\AppData\\Local\\Temp\\pip-req-build-wq9fmx1f'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/minimaxir/gpt-2-simple\n",
      "  Cloning https://github.com/minimaxir/gpt-2-simple to c:\\users\\ferna\\appdata\\local\\temp\\pip-req-build-wq9fmx1f\n",
      "  Resolved https://github.com/minimaxir/gpt-2-simple to commit d1e97f580cfbd53eee95066c7efed8d4476de943\n",
      "Requirement already satisfied: tensorflow>=2.5.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from gpt-2-simple==0.8.1) (2.8.0)\n",
      "Requirement already satisfied: regex in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from gpt-2-simple==0.8.1) (2022.1.18)\n",
      "Requirement already satisfied: requests in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from gpt-2-simple==0.8.1) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from gpt-2-simple==0.8.1) (4.62.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from gpt-2-simple==0.8.1) (1.22.2)\n",
      "Requirement already satisfied: toposort in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from gpt-2-simple==0.8.1) (1.7)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (2.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (58.0.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (13.0.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (3.10.0.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.13.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.43.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.24.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (3.3.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.5.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (3.19.4)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.16.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (2.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (2.6.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from requests->gpt-2-simple==0.8.1) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from requests->gpt-2-simple==0.8.1) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from requests->gpt-2-simple==0.8.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from requests->gpt-2-simple==0.8.1) (2.0.12)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tqdm->gpt-2-simple==0.8.1) (0.4.4)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgWDuRBNnMyu"
   },
   "source": [
    "## Text Generation\n",
    "\n",
    "There are two ways of generating text with GPT-2 by using either standard pretrained models or those you finetuned on your texts.\n",
    "\n",
    "In this notebook we will use standard models, but we will play with finetuning later (in another workshop)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FxA3S-zhofDl",
    "cellView": "form"
   },
   "source": [
    "#@title Load Pretrained Model\n",
    "\n",
    "#@markdown There are four released sizes of GPT-2 that we can use to generate text in Colab:\n",
    "\n",
    "#@markdown * `124M` (default): the \"small\" model, 500MB on disk.\n",
    "#@markdown * `355M`: the \"medium\" model, 1.5GB on disk.\n",
    "#@markdown * `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model\n",
    "#@markdown * `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook. Also, like `774M`, it cannot be finetuned in Colab.\n",
    "\n",
    "#@markdown Larger model has more knowledge, but takes longer to generate text. You can specify which base model to use by changing `model_name`.\n",
    "\n",
    "model_name = \"1558M\" #@param [\"124M\", \"355M\", \"774M\", \"1558M\"] {allow-input: true}\n",
    "\n",
    "#@markdown This cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
    "\n",
    "#@markdown This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time.\n",
    "\n",
    "gpt2.download_gpt2(model_name=model_name)\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, model_name=model_name)\n",
    "\n",
    "#@markdown *__Select the model and run the cell to load it__*"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 525Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:01, 585kit/s]                                                    \n",
      "Fetching hparams.json: 1.05Mit [00:00, 523Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 6.23Git [2:41:53, 641kit/s]                                \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 12.4Mit/s]                                               \n",
      "Fetching model.ckpt.meta: 2.10Mit [00:02, 772kit/s]                                                 \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 1.27Mit/s]                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model models\\1558M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models\\1558M\\model.ckpt\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dIjEWLn2qKbG",
    "cellView": "form",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#@title Generation with the pretrained models\n",
    "#@markdown **Generation parameters**\n",
    "\n",
    "#@markdown You can pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there\n",
    "prefix = 'The form of a soul is ' #@param {type: \"string\"}\n",
    "#@markdown Number of tokens to generate (default 1023, the maximum)\n",
    "length = 200  #@param {type:\"slider\", min:1, max:1023, step:1}\n",
    "#@markdown The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
    "temperature=0.8  #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
    "#@markdown Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
    "top_k=0  #@param {type: \"number\"}\n",
    "#@markdown Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
    "top_p=0.9  #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "#@markdown Number of samples to generate\n",
    "nsamples=10  #@param {type: \"number\"}\n",
    "#@markdown Number of samples to generate in pararallel to speed up the process\n",
    "batch_size=5  #@param {type:\"slider\", min:1, max:20, step:1}\n",
    "#@markdown Save samples to text file\n",
    "save_to_file = False #@param {type:\"boolean\"}\n",
    "\n",
    "\n",
    "#@markdown *__Set parameters and  and run the cell to generate samples__*\n",
    "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
    "gpt2.generate(sess,\n",
    "              model_name=model_name,\n",
    "              destination_path=gen_file,\n",
    "              prefix=None if prefix=='' else prefix,\n",
    "              length=length,\n",
    "              temperature=temperature,\n",
    "              top_k=int(top_k),\n",
    "              top_p=top_p,\n",
    "              nsamples=int(nsamples),\n",
    "              batch_size=batch_size\n",
    "              )"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u1e63' in position 22: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnicodeEncodeError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_7860/2220792614.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;31m#@markdown *__Set parameters and  and run the cell to generate samples__*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[0mgen_file\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdatetime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutcnow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m gpt2.generate(sess,\n\u001B[0m\u001B[0;32m     25\u001B[0m               \u001B[0mmodel_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m               \u001B[0mdestination_path\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgen_file\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages\\gpt_2_simple\\gpt_2.py\u001B[0m in \u001B[0;36mgenerate\u001B[1;34m(sess, run_name, checkpoint_dir, model_name, model_dir, sample_dir, return_as_list, truncate, destination_path, sample_delim, prefix, seed, nsamples, batch_size, length, temperature, top_k, top_p, include_prefix)\u001B[0m\n\u001B[0;32m    499\u001B[0m             \u001B[0mgen_text\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgen_text\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstrip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    500\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mdestination_path\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 501\u001B[1;33m                 \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"{}\\n{}\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgen_text\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_delim\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    502\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mreturn_as_list\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mdestination_path\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    503\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"{}\\n{}\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgen_text\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_delim\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m''\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\current-x-futurly\\lib\\encodings\\cp1252.py\u001B[0m in \u001B[0;36mencode\u001B[1;34m(self, input, final)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mIncrementalEncoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcodecs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIncrementalEncoder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mencode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfinal\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mcodecs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcharmap_encode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mencoding_table\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mIncrementalDecoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcodecs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIncrementalDecoder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnicodeEncodeError\u001B[0m: 'charmap' codec can't encode character '\\u1e63' in position 22: character maps to <undefined>"
     ]
    }
   ]
  }
 ]
}