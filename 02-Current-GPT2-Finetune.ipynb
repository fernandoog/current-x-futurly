{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "02-Current-GPT2-Finetune.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw6Oj_4oGguf"
   },
   "source": [
    "# Current.cam workshop - Volumetric Personas\n",
    "## GPT-2 Finetuning\n",
    "\n",
    "Made by [Artem Konevskikh](http://aiculedssul.net/) for [Current.cam](https://current.cam/)\n",
    "\n",
    "Based on notebook by [Max Woolf](http://minimaxir.com). For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2DuOMM9KKkQ"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tEjGHeo1GeCW",
    "cellView": "form"
   },
   "source": [
    "#@title Imports\n",
    "#@markdown By running this cell we are loading libraries needed to work with GPT2\n",
    "!pip install git+https://github.com/minimaxir/gpt-2-simple\n",
    "import gpt_2_simple as gpt2\n",
    "from datetime import datetime\n",
    "import shutil"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/minimaxir/gpt-2-simple\n",
      "  Cloning https://github.com/minimaxir/gpt-2-simple to c:\\users\\ferna\\appdata\\local\\temp\\pip-req-build-x1b_ft6r\n",
      "  Resolved https://github.com/minimaxir/gpt-2-simple to commit d1e97f580cfbd53eee95066c7efed8d4476de943\n",
      "Requirement already satisfied: tensorflow>=2.5.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from gpt-2-simple==0.8.1) (2.8.0)\n",
      "Requirement already satisfied: regex in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from gpt-2-simple==0.8.1) (2022.1.18)\n",
      "Requirement already satisfied: requests in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from gpt-2-simple==0.8.1) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from gpt-2-simple==0.8.1) (4.62.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from gpt-2-simple==0.8.1) (1.22.2)\n",
      "Requirement already satisfied: toposort in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from gpt-2-simple==0.8.1) (1.7)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.43.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (13.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.24.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (2.8.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (3.6.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (3.19.4)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.5.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (58.0.4)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.13.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.2.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (3.10.0.2)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorflow>=2.5.1->gpt-2-simple==0.8.1) (2.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (2.6.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from requests->gpt-2-simple==0.8.1) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from requests->gpt-2-simple==0.8.1) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from requests->gpt-2-simple==0.8.1) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from requests->gpt-2-simple==0.8.1) (2020.6.20)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.5.1->gpt-2-simple==0.8.1) (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ferna\\anaconda3\\envs\\current-x-futurly\\lib\\site-packages (from tqdm->gpt-2-simple==0.8.1) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/minimaxir/gpt-2-simple 'C:\\Users\\ferna\\AppData\\Local\\Temp\\pip-req-build-x1b_ft6r'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BSFvBs0NIALD",
    "cellView": "form"
   },
   "source": [
    "#@title Downloading GPT-2\n",
    "#@markdown If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
    "\n",
    "#@markdown There are two released sizes of GPT-2 that we can work with in Colab:\n",
    "\n",
    "#@markdown * `124M` (default): the \"small\" model, 500MB on disk.\n",
    "#@markdown * `355M`: the \"medium\" model, 1.5GB on disk.\n",
    "\n",
    "#@markdown Larger model has more knowledge, but takes longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name`.\n",
    "\n",
    "model_name = \"355M\" #@param [\"124M\", \"355M\"] {allow-input: true}\n",
    "\n",
    "#@markdown This cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
    "\n",
    "#@markdown This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time.\n",
    "\n",
    "\n",
    "gpt2.download_gpt2(model_name=model_name)\n"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 209Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:01, 770kit/s]                                                    \n",
      "Fetching hparams.json: 1.05Mit [00:00, 210Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 1.42Git [32:54, 719kit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 175Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:01, 717kit/s]                                                 \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 1.28Mit/s]                                                      \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPC9ylUAIpV7"
   },
   "source": [
    "### Dataset Text File\n",
    "\n",
    "To finetune GPT2 on your texts you should prepare a single plain text file. Collect the books and articles and copy all of them to this text file.\n",
    "\n",
    "GPT2 works with `.txt` files only, so this link https://www.pdf2go.com/pdf-to-text might be useful if you have your books in `pdf` format.\n",
    "\n",
    "There are two ways to load training data - directly to this notebook or from Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ODs12IJPOAYS",
    "cellView": "form"
   },
   "source": [
    "#@title Uploading a Text File directly to Colaboratory\n",
    "\n",
    "#@markdown First way is good if you have file less than 10mb. To upload file go to the Colaboratory Notebook sidebar on the left of the screen, select *Files* (folder icon) and use *Upload* button or drag-n-drop file directly to the files list\n",
    "\n",
    "#@markdown Then copy file path to the input below and run this cell\n",
    "\n",
    "file_name = '/content/all_16.02' #@param {type: \"string\"}"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zx-ZoN8ePv7c"
   },
   "source": [
    "## Finetune GPT-2\n",
    "\n",
    "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
    "\n",
    "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
    "\n",
    "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "upQj_LvDRtFU",
    "cellView": "form"
   },
   "source": [
    "#@title Set parameters\n",
    "\n",
    "#@markdown **Model**\n",
    "\n",
    "#@markdown Choose model name you downloaded before\n",
    "model_name=\"355M\" #@param [\"124M\", \"355M\"] {allow-input: true}\n",
    "\n",
    "#@markdown Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
    "restore_from='fresh' #@param [\"fresh\", \"latest\"] {allow-input: true}\n",
    "\n",
    "#@markdown Run name. Subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
    "run_name='gpt-ai' #@param {type: \"string\"}\n",
    "\n",
    "#@markdown **Steps**\n",
    "\n",
    "#@markdown Number of steps to train the model.\n",
    "steps=200 #@param {type: \"number\"}\n",
    "\n",
    "#@markdown Number of steps to print example output\n",
    "sample_every=30 #@param {type: \"number\"}\n",
    "\n",
    "#@markdown Number of steps to save the model.\n",
    "save_every=50 #@param {type: \"number\"}\n",
    "\n",
    "#@markdown Number of steps to print training progress.\n",
    "print_every=10 #@param {type: \"number\"}\n",
    "\n",
    "#@markdown **Other**\n",
    "\n",
    "#@markdown Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
    "learning_rate=0.000055 #@param {type:\"slider\", min:1e-5, max:1e-4, step:4.5e-5}\n",
    "\n",
    "#@markdown Check if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. \n",
    "overwrite=True #@param {type: \"boolean\"}\n",
    "\n",
    "use_memory_saving_gradients = True\n",
    "only_train_transformer_layers = True\n",
    "accumulate_gradients = 1"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hN72iY8QXONA",
    "cellView": "form",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#@title Run finetuning\n",
    "#@markdown **IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports and settings but not recopy files.\n",
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name=model_name,\n",
    "              steps=steps,\n",
    "              restore_from=restore_from,\n",
    "              run_name=run_name,\n",
    "              print_every=print_every,\n",
    "              sample_every=sample_every,\n",
    "              save_every=save_every,\n",
    "              learning_rate=learning_rate,\n",
    "              overwrite=overwrite,\n",
    "              )"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpt2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_15656/1303547014.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#@title Run finetuning\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m#@markdown **IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports and settings but not recopy files.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0msess\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgpt2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart_tf_sess\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m gpt2.finetune(sess,\n",
      "\u001B[1;31mNameError\u001B[0m: name 'gpt2' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}